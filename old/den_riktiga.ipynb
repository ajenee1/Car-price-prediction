{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1757259064003,
     "user": {
      "displayName": "Alexander Jenee",
      "userId": "10994353086826586405"
     },
     "user_tz": -120
    },
    "id": "d1wtk_AbkMxy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWzgsdejkoVn"
   },
   "outputs": [],
   "source": [
    "\"Read in data\"\n",
    "df = pd.read_csv(\"car_sales_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1757255512673,
     "user": {
      "displayName": "Alexander Jenee",
      "userId": "10994353086826586405"
     },
     "user_tz": -120
    },
    "id": "ogB_aUmblcGE",
    "outputId": "34a70356-1dce-43c4-cd75-45f5f68b9397"
   },
   "outputs": [],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns & dtypes:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Adding features\"\n",
    "\n",
    "age = df[\"Car_Age\"] = 2022 - df[\"Year of manufacture\"] # avoid division by zero -> turn 0 age into NaN\n",
    "\n",
    "df[\"Mileage_per_Year\"] = df[\"Mileage\"].div(age)\n",
    "\n",
    "# replace any remaining inf with NaN, then fill with total mileage\n",
    "df[\"Mileage_per_Year\"] = (\n",
    "    df[\"Mileage_per_Year\"]\n",
    "      .replace([np.inf, -np.inf], np.nan)\n",
    "      .fillna(df[\"Mileage\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1757258137910,
     "user": {
      "displayName": "Alexander Jenee",
      "userId": "10994353086826586405"
     },
     "user_tz": -120
    },
    "id": "ADc4uDVXvWj3",
    "outputId": "fabe220a-fc6e-4885-cdd7-be8069d500d5"
   },
   "outputs": [],
   "source": [
    "#check duplicates\n",
    "print(\"Total duplicates:\", df.duplicated().sum())\n",
    "\n",
    "\n",
    "duplicates = df[df.duplicated()] #display all duplicate rows\n",
    "print(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1757258172611,
     "user": {
      "displayName": "Alexander Jenee",
      "userId": "10994353086826586405"
     },
     "user_tz": -120
    },
    "id": "ug27xIJJv2Ia",
    "outputId": "b35f6694-9816-44cf-d30e-58615804e121"
   },
   "outputs": [],
   "source": [
    "\"Duplicates\"\n",
    "\n",
    "#drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"After dropping exact duplicates:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"check missing values per column\"\n",
    "\n",
    "print(\"\\nMissing values per column:\\n\", df.isna().sum())\n",
    "\n",
    "inf_counts = np.isinf(df.select_dtypes(include=[np.number])).sum()\n",
    "print(\"\\nInfinite values per numeric column:\\n\", inf_counts)\n",
    "\n",
    "# Combined check (NaN + Inf)\n",
    "bad_values = df.isna().sum() + np.isinf(df.select_dtypes(include=[np.number])).reindex(df.columns, fill_value=0)\n",
    "print(\"\\nTotal problematic values (NaN + Inf) per column:\\n\", bad_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1757259252326,
     "user": {
      "displayName": "Alexander Jenee",
      "userId": "10994353086826586405"
     },
     "user_tz": -120
    },
    "id": "rto62NQ9v-0p",
    "outputId": "e7e719a1-0bd6-4215-f76f-66bc80f79872"
   },
   "outputs": [],
   "source": [
    "\"Number and percentage of every manufacturer\"\n",
    "\n",
    "# Group by manufacturer and count\n",
    "counts = df[\"Manufacturer\"].value_counts()\n",
    "\n",
    "counts_df = counts.rename(\"Count\").to_frame()\n",
    "counts_df[\"Percentage\"] = (counts_df[\"Count\"] / counts_df[\"Count\"].sum() * 100).round(2)\n",
    "\n",
    "print(\"Cars per manufacturer:\")\n",
    "print(counts_df)\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(10,6))\n",
    "palette = sns.color_palette(\"tab10\", n_colors=len(counts_df))\n",
    "\n",
    "sns.barplot(\n",
    "    y=counts_df.index,\n",
    "    x=counts_df[\"Count\"],\n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "plt.title(\"Number of cars by Manufacturer\", fontsize=14)\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Manufacturer\")\n",
    "\n",
    "for i, (count, pct) in enumerate(zip(counts_df[\"Count\"], counts_df[\"Percentage\"])):\n",
    "    plt.text(count + 100, i, f\"{count} ({pct:.1f}%)\",\n",
    "             ha=\"left\", va=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1757259271427,
     "user": {
      "displayName": "Alexander Jenee",
      "userId": "10994353086826586405"
     },
     "user_tz": -120
    },
    "id": "Jub64llQwjpo",
    "outputId": "aacb27eb-8769-4318-9873-93d310968333"
   },
   "outputs": [],
   "source": [
    "\"Number and percentage of every model\"\n",
    "\n",
    "#Group by Manufacturer and Model\n",
    "brand_model_counts = (\n",
    "    df.groupby([\"Manufacturer\", \"Model\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "brand_model_counts[\"percentage\"] = (\n",
    "    brand_model_counts\n",
    "    .groupby(\"Manufacturer\")[\"count\"]\n",
    "    .transform(lambda x: (x / x.sum() * 100).round(2))\n",
    ")\n",
    "\n",
    "#Sort by manufacturer\n",
    "brand_model_counts = brand_model_counts.sort_values(\n",
    "    [\"Manufacturer\", \"count\"], ascending=[True, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"\\nSorted with percentages:\\n\")\n",
    "print(brand_model_counts.to_string(index=False))\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.barplot(\n",
    "    data=brand_model_counts,\n",
    "    x=\"Model\",\n",
    "    y=\"count\",\n",
    "    hue=\"Manufacturer\",\n",
    "    dodge=False,\n",
    "    palette=\"tab10\"\n",
    ")\n",
    "plt.title(\"Distribution of Models within Manufacturers\", fontsize=16)\n",
    "plt.ylabel(\"Number of Cars\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend(title=\"Manufacturer\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1757263943088,
     "user": {
      "displayName": "Alexander Jenee",
      "userId": "10994353086826586405"
     },
     "user_tz": -120
    },
    "id": "gU1yvAUMl6Pi",
    "outputId": "1bc1dbbe-cd4f-4b2f-b527-8bb9cce42219"
   },
   "outputs": [],
   "source": [
    "\"Identify numeric and categorical cols\"\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "print(\"\\nNumeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1757263947711,
     "user": {
      "displayName": "Alexander Jenee",
      "userId": "10994353086826586405"
     },
     "user_tz": -120
    },
    "id": "UH13X0PHEawH",
    "outputId": "27c10bfa-dc35-41d3-e899-55ff96cd4391"
   },
   "outputs": [],
   "source": [
    "\"Correlation matrix of numerical fuetures\"\n",
    "\n",
    "#only numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number])\n",
    "\n",
    "corr = numeric_cols.corr(method=\"pearson\").round(2)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.heatmap(\n",
    "    corr,\n",
    "    annot=True, fmt=\".2f\",\n",
    "    cmap=\"coolwarm\", vmin=-1, vmax=1,\n",
    "    square=True,\n",
    "    cbar_kws={\"shrink\": 0.9}\n",
    ")\n",
    "ax.set_title(\"Correlation matrix of numerical variables\", fontsize=14, pad=12)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Configure features and target\"\n",
    "# Define target column\n",
    "target_col = \"Price\"\n",
    "\n",
    "# Split features/target\n",
    "x = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Split data into training and test sets\"\n",
    "# Split: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Preprocess data\"\n",
    "print(f\"Original X_train shape: {X_train.shape}\")\n",
    "print(f\"Data types:\\n{X_train.dtypes}\")\n",
    "\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "X_train_processed = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test_processed = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# Update variables for cross-validation\n",
    "X_train = X_train_processed\n",
    "X_test = X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Cross-validation setup\"\n",
    "k_folds = 5 # Number of folds\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define parameter grid to test \n",
    "param_combinations = [\n",
    "    {'learning_rate': 0.001, 'batch_size': 32, 'epochs': 50, 'hidden_size': 64},\n",
    "    {'learning_rate': 0.01, 'batch_size': 32, 'epochs': 50, 'hidden_size': 128},\n",
    "    {'learning_rate': 0.001, 'batch_size': 64, 'epochs': 100, 'hidden_size': 64},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Cross-validation function\"\n",
    "def cv_params(X_train, y_train, param_list, k_folds=5):\n",
    "    \"\"\"Cross-validation for neural network hyperparameters\"\"\"\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    best_score, best_params = float('inf'), None\n",
    "    \n",
    "    for i, params in enumerate(param_list):\n",
    "        print(f\"\\nTesting {i+1}/{len(param_list)}: {params}\")\n",
    "        scores = []\n",
    "        \n",
    "        # Split and scale data\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "            scaler = StandardScaler()\n",
    "            X_tr = scaler.fit_transform(X_train.iloc[train_idx])\n",
    "            X_val = scaler.transform(X_train.iloc[val_idx])\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            # Build model\n",
    "            model = Sequential([\n",
    "                Dense(params['hidden_size'], activation='relu', input_dim=X_tr.shape[1]),\n",
    "                Dense(params['hidden_size']//2, activation='relu'),\n",
    "                Dense(params['hidden_size']//4, activation='relu'),\n",
    "                Dense(1)\n",
    "            ])\n",
    "            model.compile(optimizer=Adam(learning_rate=params['learning_rate']), loss='mse')\n",
    "            \n",
    "            # Train\n",
    "            model.fit(X_tr, y_tr, epochs=params['epochs'], batch_size=params['batch_size'],\n",
    "                     validation_data=(X_val, y_val), verbose=0,\n",
    "                     callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "            \n",
    "            # Evaluate\n",
    "            score = mean_squared_error(y_val, model.predict(X_val, verbose=0))\n",
    "            scores.append(score)\n",
    "            print(f\"  Fold {fold+1}: {score:.4f}\")\n",
    "        \n",
    "        # Track best\n",
    "        avg_score = np.mean(scores)\n",
    "        print(f\"  Average: {avg_score:.4f} ¬± {np.std(scores):.4f}\")\n",
    "        \n",
    "        if avg_score < best_score:\n",
    "            best_score, best_params = avg_score, params\n",
    "    \n",
    "    print(f\"Best: {best_params} (MSE: {best_score:.4f})\")\n",
    "    return best_params, best_score, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Run cross-validation to find best parameters\"\n",
    "best_params, best_score, all_results = cv_params(\n",
    "    X_train, y_train, \n",
    "    param_combinations, \n",
    "    k_folds=5\n",
    ")\n",
    "\n",
    "print(\"\\nAll parameter combinations tested:\")\n",
    "for i, result in enumerate(all_results):\n",
    "    print(f\"\\n{i+1}. {result['params']}\")\n",
    "    print(f\"   Average MSE: {result['avg_score']:.4f} ¬± {result['std_score']:.4f}\")\n",
    "    print(f\"   Fold scores: {[f'{score:.4f}' for score in result['fold_scores']]}\")\n",
    "\n",
    "# Print best parameters\n",
    "print(f\"   BEST PARAMETERS FOUND:\")\n",
    "print(f\"   Parameters: {best_params}\")\n",
    "print(f\"   Best CV Score (MSE): {best_score:.4f}\")\n",
    "print(f\"   Best CV Score (RMSE): {np.sqrt(best_score):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Training final model with best parameters\"\n",
    "\n",
    "# Scale the full training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create final model with best params\n",
    "def create_final_model(params, input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(params['hidden_size'], activation='relu', input_dim=input_dim),\n",
    "        Dense(params['hidden_size']//2, activation='relu'),\n",
    "        Dense(params['hidden_size']//4, activation='relu'),\n",
    "        Dense(1)  # Output layer for regression\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=params['learning_rate']),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Train final model\n",
    "final_model = create_final_model(best_params, X_train_scaled.shape[1])\n",
    "\n",
    "history = final_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=best_params['epochs'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    validation_split=0.2,  # Use 20% of training data for monitoring\n",
    "    verbose=1,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "print(\"Final model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Evaluate final model on test set\"\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = final_model.predict(X_test_scaled, verbose=0)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "# Print results\n",
    "print(f\"   Final test results:\")\n",
    "print(f\"   Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"   Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"   Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"   R¬≤ Score: {r2:.4f}\")\n",
    "\n",
    "print(f\"   Comparison:\")\n",
    "print(f\"   Cross-Validation RMSE: {np.sqrt(best_score):.4f}\")\n",
    "print(f\"   Final Test RMSE: {rmse:.4f}\")\n",
    "print(f\"   Difference: {abs(rmse - np.sqrt(best_score)):.4f}\")\n",
    "\n",
    "# Plot (predictions vs actual)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, test_predictions, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Final Model: Actual vs Predicted Prices')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Save model\"\n",
    "final_model.save('price_prediction_model.keras') \n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "\n",
    "# Metadata\n",
    "model_info = {\n",
    "    'best_params': best_params,\n",
    "    'best_score': best_score,\n",
    "    'feature_names': list(X_train.columns),\n",
    "    'model_type': 'neural_network'\n",
    "}\n",
    "joblib.dump(model_info, 'model_info.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Function to predict on new data\"\n",
    "def predict_price(new_data):\n",
    "    new_data_scaled = scaler.transform(new_data)\n",
    "    prediction = final_model.predict(new_data_scaled)\n",
    "    return prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Example\"\n",
    "new_car_data = pd.DataFrame({\n",
    "    'Make': ['Toyota'],\n",
    "    'Model': ['Camry'], \n",
    "    'Year': [2023],\n",
    "    'Mileage': [25000],\n",
    "    'Engine_Size': [2.5],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Test prediction on samples from test set\"\n",
    "\n",
    "sample_new_data = X_test.iloc[:5].copy()  # Test samples\n",
    "actual_prices = y_test.iloc[:5].copy()    # Actual prices (for comparison)\n",
    "\n",
    "\n",
    "for i in range(len(sample_new_data)):\n",
    "    sample_scaled = scaler.transform([sample_new_data.iloc[i]])\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_price = final_model.predict(sample_scaled, verbose=0)[0][0]\n",
    "    actual_price = actual_prices.iloc[i]\n",
    "    \n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  Predicted Price: ${predicted_price:,.2f}\")\n",
    "    print(f\"  Actual Price: ${actual_price:,.2f}\")\n",
    "    print(f\"  Error: ${abs(predicted_price - actual_price):,.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"SHAP\"\n",
    "# Use smaller sample for faster computation\n",
    "n_background = 50  # Background samples\n",
    "n_explain = 10     # Samples to explain\n",
    "\n",
    "# Create wrapper function\n",
    "def model_predict_shap(X):\n",
    "    return final_model.predict(X, verbose=0).flatten()\n",
    "\n",
    "# Use KernelExplainer instead of DeepExplainer\n",
    "explainer = shap.KernelExplainer(model_predict_shap, X_train_scaled[:n_background])\n",
    "shap_values = explainer.shap_values(X_test_scaled[:n_explain])\n",
    "\n",
    "# Simple feature importance from SHAP\n",
    "feature_importance = np.mean(np.abs(shap_values), axis=0)\n",
    "shap_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'SHAP_Importance': feature_importance\n",
    "}).sort_values('SHAP_Importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Features by SHAP:\")\n",
    "print(shap_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"ANV√ÑND F√ñR RAPPORT\"\n",
    "\n",
    "# Calculate SHAP feature importance (your existing code)\n",
    "feature_importance = np.mean(np.abs(shap_values), axis=0)\n",
    "shap_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'SHAP_Importance': feature_importance\n",
    "}).sort_values('SHAP_Importance', ascending=False)\n",
    "\n",
    "# Much clearer output\n",
    "print(\"=\" * 70)\n",
    "print(\"üéØ SHAP FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Ranking features by their average impact on price predictions\")\n",
    "print(\"Higher values = more influential on model decisions\")\n",
    "print()\n",
    "\n",
    "print(\"üìä TOP 15 MOST INFLUENTIAL FEATURES:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Rank':>4} {'Feature':.<35} {'SHAP Score':>12} {'% of Total':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Calculate percentages\n",
    "total_importance = shap_df['SHAP_Importance'].sum()\n",
    "\n",
    "for i, (idx, row) in enumerate(shap_df.head(15).iterrows(), 1):\n",
    "    feature = row['Feature']\n",
    "    importance = row['SHAP_Importance']\n",
    "    percentage = (importance / total_importance) * 100\n",
    "    \n",
    "    print(f\"{i:>4}. {feature:.<34} {importance:>10.1f} {percentage:>8.1f}%\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'':>4} {'TOTAL (Top 15)':.<34} {shap_df.head(15)['SHAP_Importance'].sum():>10.1f} {(shap_df.head(15)['SHAP_Importance'].sum()/total_importance)*100:>8.1f}%\")\n",
    "\n",
    "# Key insights\n",
    "print()\n",
    "print(\"üîç KEY INSIGHTS:\")\n",
    "top_3 = shap_df.head(3)\n",
    "print(f\"‚Ä¢ Top 3 features ({', '.join(top_3['Feature'].tolist())}) account for {(top_3['SHAP_Importance'].sum()/total_importance)*100:.1f}% of model decisions\")\n",
    "print(f\"‚Ä¢ {shap_df['Feature'].iloc[0]} is the most critical factor (index {shap_df.index[0]})\")\n",
    "print(f\"‚Ä¢ Model uses {len(shap_df)} total features, but top 10 drive {(shap_df.head(10)['SHAP_Importance'].sum()/total_importance)*100:.1f}% of predictions\")\n",
    "\n",
    "print()\n",
    "print(\"üí° INTERPRETATION:\")\n",
    "print(\"‚Ä¢ Physical wear (Mileage, Car_Age) dominate pricing decisions\")\n",
    "print(\"‚Ä¢ Luxury models (M5, Porsche) create significant price premiums\")  \n",
    "print(\"‚Ä¢ Brand and model matter more than basic specs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Feature importance by permutation\"\n",
    "baseline_predictions = final_model.predict(X_test_scaled, verbose=0).flatten()\n",
    "baseline_mse = mean_squared_error(y_test, baseline_predictions)\n",
    "\n",
    "# Calculate importance for each feature\n",
    "feature_importance_scores = []\n",
    "\n",
    "for i, feature_name in enumerate(X_train.columns):\n",
    "    X_test_permuted = X_test_scaled.copy()\n",
    "    np.random.seed(42)\n",
    "    X_test_permuted[:, i] = np.random.permutation(X_test_permuted[:, i])\n",
    "    \n",
    "    # Make predictions with shuffled feature\n",
    "    permuted_predictions = final_model.predict(X_test_permuted, verbose=0).flatten()\n",
    "    permuted_mse = mean_squared_error(y_test, permuted_predictions)\n",
    "    \n",
    "    # Calculate importance (increase in error)\n",
    "    importance = permuted_mse - baseline_mse\n",
    "    feature_importance_scores.append(importance)\n",
    "    \n",
    "    if i % 10 == 0: \n",
    "        print(f\"  Processed {i+1}/{len(X_train.columns)} features...\")\n",
    "\n",
    "# Results dataframe\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importance_scores\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"‚úÖ Feature importance calculated!\")\n",
    "\n",
    "# Plot (top features)\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance_df.head(100)\n",
    "\n",
    "plt.barh(range(len(top_features)), top_features['Importance'], \n",
    "         alpha=0.7, color='lightcoral')\n",
    "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "plt.xlabel('Importance (Increase in MSE when feature is shuffled)')\n",
    "plt.title('Top 15 Most Important Features for Price Prediction')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Most Important Features:\")\n",
    "for i, (idx, row) in enumerate(feature_importance_df.head(100).iterrows()):\n",
    "    print(f\"{i+1:2d}. {row['Feature']:35} {row['Importance']:8.4f}\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"- Higher values = more important for accurate predictions\")\n",
    "print(f\"- These features cause the biggest performance drop when shuffled\")\n",
    "print(f\"- Negative values mean shuffling actually improved performance (rare)\")\n",
    "\n",
    "# Percentage contribution\n",
    "total_importance = feature_importance_df['Importance'].sum()\n",
    "feature_importance_df['Percentage'] = (feature_importance_df['Importance'] / total_importance * 100).round(2)\n",
    "\n",
    "print(f\"\\nTop 5 Features by Percentage Contribution:\")\n",
    "for i, (idx, row) in enumerate(feature_importance_df.head(5).iterrows()):\n",
    "    print(f\"{i+1}. {row['Feature']:35} {row['Percentage']:5.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicates: 12\n",
      "      Manufacturer   Model  Engine size Fuel type  Year of manufacture  \\\n",
      "5426            VW    Polo          1.2    Petrol                 2003   \n",
      "9862          Ford  Mondeo          1.4    Diesel                 1987   \n",
      "14745          BMW      Z4          2.4    Petrol                 1999   \n",
      "19020       Toyota   Yaris          1.0    Petrol                 1996   \n",
      "19337           VW    Polo          1.0    Petrol                 2000   \n",
      "23927           VW    Polo          1.2    Petrol                 2021   \n",
      "25368           VW    Golf          1.2    Diesel                 2011   \n",
      "28576           VW    Polo          1.2    Petrol                 2003   \n",
      "34246           VW  Passat          2.0    Diesel                 2003   \n",
      "35647         Ford   Focus          1.6    Petrol                 2019   \n",
      "41536           VW  Passat          1.8    Diesel                 1996   \n",
      "45904         Ford  Fiesta          1.2    Petrol                 2003   \n",
      "\n",
      "       Mileage  Price  Car_Age  Mileage_per_Year  \n",
      "5426     10000   8024       19        526.315789  \n",
      "9862    224569    883       35       6416.257143  \n",
      "14745    12000  13410       23        521.739130  \n",
      "19020    13500   5087       26        519.230769  \n",
      "19337    11500   5950       22        522.727273  \n",
      "23927     1000  27901        1       1000.000000  \n",
      "25368     6000  17401       11        545.454545  \n",
      "28576    10000   8024       19        526.315789  \n",
      "34246    10000  16087       19        526.315789  \n",
      "35647     2000  39636        3        666.666667  \n",
      "41536    13500   9394       26        519.230769  \n",
      "45904   124092   3691       19       6531.157895  \n",
      "After dropping exact duplicates: (49988, 9)\n"
     ]
    }
   ],
   "source": [
    "from testtttt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Engine size</th>\n",
       "      <th>Fuel type</th>\n",
       "      <th>Year of manufacture</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Price</th>\n",
       "      <th>Car_Age</th>\n",
       "      <th>Mileage_per_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford</td>\n",
       "      <td>Fiesta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>2002</td>\n",
       "      <td>127300</td>\n",
       "      <td>3074</td>\n",
       "      <td>20</td>\n",
       "      <td>6365.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Porsche</td>\n",
       "      <td>718 Cayman</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>2016</td>\n",
       "      <td>57850</td>\n",
       "      <td>49704</td>\n",
       "      <td>6</td>\n",
       "      <td>9641.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ford</td>\n",
       "      <td>Mondeo</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>2014</td>\n",
       "      <td>39190</td>\n",
       "      <td>24072</td>\n",
       "      <td>8</td>\n",
       "      <td>4898.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>RAV4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>1988</td>\n",
       "      <td>210814</td>\n",
       "      <td>1705</td>\n",
       "      <td>34</td>\n",
       "      <td>6200.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VW</td>\n",
       "      <td>Polo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>2006</td>\n",
       "      <td>127869</td>\n",
       "      <td>4101</td>\n",
       "      <td>16</td>\n",
       "      <td>7991.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>BMW</td>\n",
       "      <td>M5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>2018</td>\n",
       "      <td>28664</td>\n",
       "      <td>113006</td>\n",
       "      <td>4</td>\n",
       "      <td>7166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Prius</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>2003</td>\n",
       "      <td>105120</td>\n",
       "      <td>9430</td>\n",
       "      <td>19</td>\n",
       "      <td>5532.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Ford</td>\n",
       "      <td>Mondeo</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>2022</td>\n",
       "      <td>4030</td>\n",
       "      <td>49852</td>\n",
       "      <td>0</td>\n",
       "      <td>4030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Ford</td>\n",
       "      <td>Focus</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>2016</td>\n",
       "      <td>26468</td>\n",
       "      <td>23630</td>\n",
       "      <td>6</td>\n",
       "      <td>4411.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>VW</td>\n",
       "      <td>Golf</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>2012</td>\n",
       "      <td>109300</td>\n",
       "      <td>10400</td>\n",
       "      <td>10</td>\n",
       "      <td>10930.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49988 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Manufacturer       Model  Engine size Fuel type  Year of manufacture  \\\n",
       "0             Ford      Fiesta          1.0    Petrol                 2002   \n",
       "1          Porsche  718 Cayman          4.0    Petrol                 2016   \n",
       "2             Ford      Mondeo          1.6    Diesel                 2014   \n",
       "3           Toyota        RAV4          1.8    Hybrid                 1988   \n",
       "4               VW        Polo          1.0    Petrol                 2006   \n",
       "...            ...         ...          ...       ...                  ...   \n",
       "49995          BMW          M5          5.0    Petrol                 2018   \n",
       "49996       Toyota       Prius          1.8    Hybrid                 2003   \n",
       "49997         Ford      Mondeo          1.6    Diesel                 2022   \n",
       "49998         Ford       Focus          1.0    Diesel                 2016   \n",
       "49999           VW        Golf          1.4    Diesel                 2012   \n",
       "\n",
       "       Mileage   Price  Car_Age  Mileage_per_Year  \n",
       "0       127300    3074       20       6365.000000  \n",
       "1        57850   49704        6       9641.666667  \n",
       "2        39190   24072        8       4898.750000  \n",
       "3       210814    1705       34       6200.411765  \n",
       "4       127869    4101       16       7991.812500  \n",
       "...        ...     ...      ...               ...  \n",
       "49995    28664  113006        4       7166.000000  \n",
       "49996   105120    9430       19       5532.631579  \n",
       "49997     4030   49852        0       4030.000000  \n",
       "49998    26468   23630        6       4411.333333  \n",
       "49999   109300   10400       10      10930.000000  \n",
       "\n",
       "[49988 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
