{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83b93a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_net_car_price.py\n",
    "# Requires: pandas, numpy, scikit-learn, tensorflow (>=2.x), matplotlib (optional for plots)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc9f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1) Load data\n",
    "# ---------------------------\n",
    "CSV_PATH = \"car_sales_data.csv\"   # already present for you\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Expect these columns based on your file:\n",
    "# ['Manufacturer','Model','Engine size','Fuel type','Year of manufacture','Mileage','Price']\n",
    "target_col = \"Price\"\n",
    "\n",
    "# Basic sanity checks\n",
    "df = df.dropna(subset=[target_col])  # drop rows with missing target\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88b0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 2) Split features/target\n",
    "# ---------------------------\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype(float)\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = [\"Manufacturer\", \"Model\", \"Fuel type\"]\n",
    "numeric_cols = [\"Engine size\", \"Year of manufacture\", \"Mileage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2e4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3) Preprocess\n",
    "# ---------------------------\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e610b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4) Build Keras model factory\n",
    "# ---------------------------\n",
    "def build_model(input_dim: int) -> keras.Model:\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(input_dim,)),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dense(1)  # regression output\n",
    "    ])\n",
    "    # Huber loss is robust to outliers; you can switch to \"mse\" if you prefer\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=keras.losses.Huber(),\n",
    "                  metrics=[keras.metrics.MeanAbsoluteError(name=\"MAE\")])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "787b1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 5) Train/Validation/Test split\n",
    "# ---------------------------\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.1765, random_state=42\n",
    ")\n",
    "# Now: ~70% train, ~15% val, ~15% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31a0affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 6) Fit the preprocessor and transform\n",
    "# ---------------------------\n",
    "preprocessor.fit(X_train)\n",
    "X_train_tf = preprocessor.transform(X_train)\n",
    "X_val_tf   = preprocessor.transform(X_val)\n",
    "X_test_tf  = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0700c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - MAE: 13740.4805 - loss: 13739.9805 - val_MAE: 13657.6514 - val_loss: 13657.1514 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 12755.8281 - loss: 12755.3281 - val_MAE: 11603.3164 - val_loss: 11602.8164 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - MAE: 9666.7217 - loss: 9666.2217 - val_MAE: 7882.4170 - val_loss: 7881.9175 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 6505.9673 - loss: 6505.4673 - val_MAE: 5460.1328 - val_loss: 5459.6333 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 4795.8447 - loss: 4795.3452 - val_MAE: 4277.6030 - val_loss: 4277.1030 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 3860.4519 - loss: 3859.9517 - val_MAE: 3487.3481 - val_loss: 3486.8486 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 3170.3191 - loss: 3169.8196 - val_MAE: 2903.8125 - val_loss: 2903.3127 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 2672.9587 - loss: 2672.4592 - val_MAE: 2473.5789 - val_loss: 2473.0798 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 2296.7839 - loss: 2296.2842 - val_MAE: 2132.3206 - val_loss: 2131.8213 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 2006.2372 - loss: 2005.7374 - val_MAE: 1851.3745 - val_loss: 1850.8754 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 1772.3158 - loss: 1771.8162 - val_MAE: 1625.4724 - val_loss: 1624.9728 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 1586.7173 - loss: 1586.2177 - val_MAE: 1435.5394 - val_loss: 1435.0402 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 1432.9541 - loss: 1432.4542 - val_MAE: 1279.4033 - val_loss: 1278.9041 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 1308.3489 - loss: 1307.8491 - val_MAE: 1144.6815 - val_loss: 1144.1821 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 1204.7137 - loss: 1204.2144 - val_MAE: 1034.1234 - val_loss: 1033.6241 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - MAE: 1116.9282 - loss: 1116.4288 - val_MAE: 948.8112 - val_loss: 948.3120 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 1055.4779 - loss: 1054.9784 - val_MAE: 874.2512 - val_loss: 873.7521 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 993.4145 - loss: 992.9149 - val_MAE: 808.1603 - val_loss: 807.6613 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 948.7690 - loss: 948.2697 - val_MAE: 762.2121 - val_loss: 761.7132 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 908.4890 - loss: 907.9897 - val_MAE: 718.0812 - val_loss: 717.5823 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 883.1583 - loss: 882.6588 - val_MAE: 679.0590 - val_loss: 678.5601 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 848.1771 - loss: 847.6779 - val_MAE: 641.7386 - val_loss: 641.2399 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 822.3550 - loss: 821.8557 - val_MAE: 629.1732 - val_loss: 628.6740 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 800.2010 - loss: 799.7014 - val_MAE: 595.0335 - val_loss: 594.5348 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 777.3043 - loss: 776.8051 - val_MAE: 569.3477 - val_loss: 568.8491 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 767.1474 - loss: 766.6476 - val_MAE: 551.1284 - val_loss: 550.6296 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 747.9099 - loss: 747.4103 - val_MAE: 532.3682 - val_loss: 531.8694 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 730.1128 - loss: 729.6134 - val_MAE: 512.7242 - val_loss: 512.2260 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 714.8359 - loss: 714.3367 - val_MAE: 497.1633 - val_loss: 496.6648 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 698.1278 - loss: 697.6284 - val_MAE: 492.4213 - val_loss: 491.9218 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 689.6553 - loss: 689.1558 - val_MAE: 472.6321 - val_loss: 472.1336 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 676.6688 - loss: 676.1694 - val_MAE: 455.1778 - val_loss: 454.6794 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 665.9054 - loss: 665.4059 - val_MAE: 444.1296 - val_loss: 443.6310 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 662.5117 - loss: 662.0123 - val_MAE: 433.3617 - val_loss: 432.8632 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 642.0555 - loss: 641.5563 - val_MAE: 424.9617 - val_loss: 424.4630 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 636.2433 - loss: 635.7439 - val_MAE: 406.5085 - val_loss: 406.0105 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 630.0967 - loss: 629.5973 - val_MAE: 398.9813 - val_loss: 398.4830 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 619.8593 - loss: 619.3600 - val_MAE: 384.6690 - val_loss: 384.1712 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 610.4026 - loss: 609.9034 - val_MAE: 379.2087 - val_loss: 378.7105 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 603.1985 - loss: 602.6991 - val_MAE: 364.9327 - val_loss: 364.4347 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 594.7193 - loss: 594.2201 - val_MAE: 366.5042 - val_loss: 366.0058 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 585.1381 - loss: 584.6390 - val_MAE: 349.8856 - val_loss: 349.3876 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 579.1375 - loss: 578.6382 - val_MAE: 342.9957 - val_loss: 342.4971 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 575.4510 - loss: 574.9520 - val_MAE: 331.1801 - val_loss: 330.6819 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 565.2967 - loss: 564.7973 - val_MAE: 322.6018 - val_loss: 322.1031 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 560.1198 - loss: 559.6204 - val_MAE: 315.3871 - val_loss: 314.8890 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 555.8738 - loss: 555.3746 - val_MAE: 336.9218 - val_loss: 336.4224 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 543.9453 - loss: 543.4458 - val_MAE: 311.5431 - val_loss: 311.0443 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 545.4992 - loss: 544.9998 - val_MAE: 302.3621 - val_loss: 301.8633 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 542.1332 - loss: 541.6339 - val_MAE: 299.0255 - val_loss: 298.5269 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 533.2109 - loss: 532.7115 - val_MAE: 287.1332 - val_loss: 286.6346 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 527.9352 - loss: 527.4359 - val_MAE: 278.4846 - val_loss: 277.9860 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 529.4160 - loss: 528.9166 - val_MAE: 279.7843 - val_loss: 279.2856 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 522.7114 - loss: 522.2119 - val_MAE: 273.4325 - val_loss: 272.9337 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 522.8759 - loss: 522.3766 - val_MAE: 284.2708 - val_loss: 283.7720 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 513.6718 - loss: 513.1724 - val_MAE: 258.4868 - val_loss: 257.9882 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 507.9047 - loss: 507.4054 - val_MAE: 255.1317 - val_loss: 254.6328 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 500.6819 - loss: 500.1825 - val_MAE: 249.0916 - val_loss: 248.5930 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 506.6310 - loss: 506.1318 - val_MAE: 242.5545 - val_loss: 242.0556 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 505.1428 - loss: 504.6435 - val_MAE: 253.3315 - val_loss: 252.8330 - learning_rate: 0.0010\n",
      "Epoch 61/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 499.2206 - loss: 498.7212 - val_MAE: 236.1281 - val_loss: 235.6299 - learning_rate: 0.0010\n",
      "Epoch 62/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 490.2625 - loss: 489.7632 - val_MAE: 232.1998 - val_loss: 231.7014 - learning_rate: 0.0010\n",
      "Epoch 63/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 487.4554 - loss: 486.9561 - val_MAE: 225.9110 - val_loss: 225.4127 - learning_rate: 0.0010\n",
      "Epoch 64/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 488.7010 - loss: 488.2017 - val_MAE: 225.9065 - val_loss: 225.4079 - learning_rate: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 495.2235 - loss: 494.7241 - val_MAE: 220.5045 - val_loss: 220.0060 - learning_rate: 0.0010\n",
      "Epoch 66/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 486.7737 - loss: 486.2745 - val_MAE: 222.9525 - val_loss: 222.4540 - learning_rate: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 481.5499 - loss: 481.0506 - val_MAE: 215.9703 - val_loss: 215.4718 - learning_rate: 0.0010\n",
      "Epoch 68/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 478.0535 - loss: 477.5541 - val_MAE: 217.6340 - val_loss: 217.1353 - learning_rate: 0.0010\n",
      "Epoch 69/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 481.1710 - loss: 480.6717 - val_MAE: 209.7879 - val_loss: 209.2894 - learning_rate: 0.0010\n",
      "Epoch 70/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 479.5794 - loss: 479.0803 - val_MAE: 221.1705 - val_loss: 220.6719 - learning_rate: 0.0010\n",
      "Epoch 71/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 477.2661 - loss: 476.7669 - val_MAE: 208.4891 - val_loss: 207.9908 - learning_rate: 0.0010\n",
      "Epoch 72/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 471.0820 - loss: 470.5826 - val_MAE: 199.6698 - val_loss: 199.1720 - learning_rate: 0.0010\n",
      "Epoch 73/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 474.1254 - loss: 473.6262 - val_MAE: 209.7156 - val_loss: 209.2170 - learning_rate: 0.0010\n",
      "Epoch 74/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 466.9655 - loss: 466.4662 - val_MAE: 197.2112 - val_loss: 196.7126 - learning_rate: 0.0010\n",
      "Epoch 75/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 468.7985 - loss: 468.2993 - val_MAE: 193.6375 - val_loss: 193.1392 - learning_rate: 0.0010\n",
      "Epoch 76/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 466.3228 - loss: 465.8235 - val_MAE: 191.6621 - val_loss: 191.1638 - learning_rate: 0.0010\n",
      "Epoch 77/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 463.3312 - loss: 462.8319 - val_MAE: 188.6115 - val_loss: 188.1133 - learning_rate: 0.0010\n",
      "Epoch 78/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 463.3743 - loss: 462.8748 - val_MAE: 194.7560 - val_loss: 194.2575 - learning_rate: 0.0010\n",
      "Epoch 79/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 457.0121 - loss: 456.5126 - val_MAE: 181.3302 - val_loss: 180.8318 - learning_rate: 0.0010\n",
      "Epoch 80/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 459.1278 - loss: 458.6284 - val_MAE: 180.7482 - val_loss: 180.2506 - learning_rate: 0.0010\n",
      "Epoch 81/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 462.5628 - loss: 462.0634 - val_MAE: 182.3296 - val_loss: 181.8311 - learning_rate: 0.0010\n",
      "Epoch 82/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 455.1064 - loss: 454.6072 - val_MAE: 174.5073 - val_loss: 174.0092 - learning_rate: 0.0010\n",
      "Epoch 83/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 453.6890 - loss: 453.1895 - val_MAE: 170.7029 - val_loss: 170.2045 - learning_rate: 0.0010\n",
      "Epoch 84/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 452.9823 - loss: 452.4831 - val_MAE: 170.9149 - val_loss: 170.4172 - learning_rate: 0.0010\n",
      "Epoch 85/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 453.7010 - loss: 453.2016 - val_MAE: 173.6015 - val_loss: 173.1031 - learning_rate: 0.0010\n",
      "Epoch 86/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 450.6786 - loss: 450.1794 - val_MAE: 166.7339 - val_loss: 166.2357 - learning_rate: 0.0010\n",
      "Epoch 87/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 451.2829 - loss: 450.7838 - val_MAE: 175.1068 - val_loss: 174.6087 - learning_rate: 0.0010\n",
      "Epoch 88/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 448.2339 - loss: 447.7347 - val_MAE: 171.6537 - val_loss: 171.1561 - learning_rate: 0.0010\n",
      "Epoch 89/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 447.4567 - loss: 446.9572 - val_MAE: 164.2305 - val_loss: 163.7328 - learning_rate: 0.0010\n",
      "Epoch 90/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 444.4688 - loss: 443.9696 - val_MAE: 163.9818 - val_loss: 163.4842 - learning_rate: 0.0010\n",
      "Epoch 91/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 445.8587 - loss: 445.3596 - val_MAE: 160.2023 - val_loss: 159.7049 - learning_rate: 0.0010\n",
      "Epoch 92/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 445.3509 - loss: 444.8518 - val_MAE: 158.7493 - val_loss: 158.2516 - learning_rate: 0.0010\n",
      "Epoch 93/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 445.9511 - loss: 445.4518 - val_MAE: 158.5123 - val_loss: 158.0144 - learning_rate: 0.0010\n",
      "Epoch 94/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 444.0206 - loss: 443.5211 - val_MAE: 158.5972 - val_loss: 158.0986 - learning_rate: 0.0010\n",
      "Epoch 95/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 444.1935 - loss: 443.6939 - val_MAE: 160.4987 - val_loss: 160.0005 - learning_rate: 0.0010\n",
      "Epoch 96/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 440.2464 - loss: 439.7470 - val_MAE: 172.3144 - val_loss: 171.8159 - learning_rate: 0.0010\n",
      "Epoch 97/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 440.5655 - loss: 440.0663 - val_MAE: 162.2959 - val_loss: 161.7978 - learning_rate: 0.0010\n",
      "Epoch 98/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 437.7693 - loss: 437.2699 - val_MAE: 148.1564 - val_loss: 147.6578 - learning_rate: 0.0010\n",
      "Epoch 99/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 440.9681 - loss: 440.4688 - val_MAE: 159.9210 - val_loss: 159.4237 - learning_rate: 0.0010\n",
      "Epoch 100/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 435.7692 - loss: 435.2699 - val_MAE: 142.9013 - val_loss: 142.4034 - learning_rate: 0.0010\n",
      "Epoch 101/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 436.0948 - loss: 435.5956 - val_MAE: 157.7061 - val_loss: 157.2083 - learning_rate: 0.0010\n",
      "Epoch 102/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 438.7846 - loss: 438.2852 - val_MAE: 163.4203 - val_loss: 162.9219 - learning_rate: 0.0010\n",
      "Epoch 103/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 435.5352 - loss: 435.0359 - val_MAE: 146.8498 - val_loss: 146.3515 - learning_rate: 0.0010\n",
      "Epoch 104/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 432.7756 - loss: 432.2763 - val_MAE: 140.2616 - val_loss: 139.7642 - learning_rate: 0.0010\n",
      "Epoch 105/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 434.1902 - loss: 433.6909 - val_MAE: 158.3988 - val_loss: 157.8996 - learning_rate: 0.0010\n",
      "Epoch 106/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 435.3806 - loss: 434.8814 - val_MAE: 144.9346 - val_loss: 144.4360 - learning_rate: 0.0010\n",
      "Epoch 107/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 433.6426 - loss: 433.1432 - val_MAE: 137.1812 - val_loss: 136.6837 - learning_rate: 0.0010\n",
      "Epoch 108/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 429.7425 - loss: 429.2433 - val_MAE: 133.7939 - val_loss: 133.2963 - learning_rate: 0.0010\n",
      "Epoch 109/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 433.1446 - loss: 432.6452 - val_MAE: 157.5400 - val_loss: 157.0420 - learning_rate: 0.0010\n",
      "Epoch 110/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 430.1695 - loss: 429.6703 - val_MAE: 133.1254 - val_loss: 132.6276 - learning_rate: 0.0010\n",
      "Epoch 111/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 425.0212 - loss: 424.5219 - val_MAE: 138.5449 - val_loss: 138.0469 - learning_rate: 0.0010\n",
      "Epoch 112/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 427.7672 - loss: 427.2679 - val_MAE: 141.0166 - val_loss: 140.5186 - learning_rate: 0.0010\n",
      "Epoch 113/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 428.4253 - loss: 427.9260 - val_MAE: 137.6440 - val_loss: 137.1459 - learning_rate: 0.0010\n",
      "Epoch 114/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 429.6468 - loss: 429.1476 - val_MAE: 135.1294 - val_loss: 134.6313 - learning_rate: 0.0010\n",
      "Epoch 115/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 430.5884 - loss: 430.0893 - val_MAE: 153.5362 - val_loss: 153.0383 - learning_rate: 0.0010\n",
      "Epoch 116/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 432.7901 - loss: 432.2909 - val_MAE: 148.1455 - val_loss: 147.6468 - learning_rate: 5.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 422.5063 - loss: 422.0070 - val_MAE: 128.9592 - val_loss: 128.4615 - learning_rate: 5.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - MAE: 430.9934 - loss: 430.4942 - val_MAE: 130.7536 - val_loss: 130.2553 - learning_rate: 5.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - MAE: 424.0561 - loss: 423.5567 - val_MAE: 130.2260 - val_loss: 129.7290 - learning_rate: 5.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 424.5119 - loss: 424.0127 - val_MAE: 147.1336 - val_loss: 146.6351 - learning_rate: 5.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 423.4565 - loss: 422.9571 - val_MAE: 132.4093 - val_loss: 131.9109 - learning_rate: 5.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 425.4773 - loss: 424.9780 - val_MAE: 128.8185 - val_loss: 128.3209 - learning_rate: 5.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 421.5204 - loss: 421.0212 - val_MAE: 134.7790 - val_loss: 134.2812 - learning_rate: 5.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 422.2206 - loss: 421.7215 - val_MAE: 124.9400 - val_loss: 124.4422 - learning_rate: 5.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 423.7707 - loss: 423.2715 - val_MAE: 135.0426 - val_loss: 134.5443 - learning_rate: 5.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 429.9645 - loss: 429.4653 - val_MAE: 130.0828 - val_loss: 129.5847 - learning_rate: 5.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 424.5811 - loss: 424.0820 - val_MAE: 125.4649 - val_loss: 124.9671 - learning_rate: 5.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 426.3133 - loss: 425.8140 - val_MAE: 121.7938 - val_loss: 121.2959 - learning_rate: 5.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 422.8386 - loss: 422.3392 - val_MAE: 142.7315 - val_loss: 142.2328 - learning_rate: 5.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 425.5028 - loss: 425.0037 - val_MAE: 121.9076 - val_loss: 121.4098 - learning_rate: 5.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 425.6169 - loss: 425.1176 - val_MAE: 125.2206 - val_loss: 124.7222 - learning_rate: 5.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 420.1592 - loss: 419.6599 - val_MAE: 125.6394 - val_loss: 125.1416 - learning_rate: 5.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 418.5087 - loss: 418.0094 - val_MAE: 123.1053 - val_loss: 122.6068 - learning_rate: 5.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 413.7368 - loss: 413.2374 - val_MAE: 121.1139 - val_loss: 120.6158 - learning_rate: 2.5000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 417.1257 - loss: 416.6264 - val_MAE: 128.7937 - val_loss: 128.2955 - learning_rate: 2.5000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 421.5775 - loss: 421.0785 - val_MAE: 137.1464 - val_loss: 136.6481 - learning_rate: 2.5000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 419.7013 - loss: 419.2021 - val_MAE: 125.7295 - val_loss: 125.2312 - learning_rate: 2.5000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 423.8177 - loss: 423.3186 - val_MAE: 125.4495 - val_loss: 124.9515 - learning_rate: 2.5000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 423.5822 - loss: 423.0827 - val_MAE: 135.3013 - val_loss: 134.8026 - learning_rate: 2.5000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 419.6702 - loss: 419.1707 - val_MAE: 134.8325 - val_loss: 134.3342 - learning_rate: 1.2500e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 419.9995 - loss: 419.5004 - val_MAE: 128.3194 - val_loss: 127.8208 - learning_rate: 1.2500e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 417.0467 - loss: 416.5476 - val_MAE: 134.4009 - val_loss: 133.9023 - learning_rate: 1.2500e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - MAE: 423.1872 - loss: 422.6883 - val_MAE: 124.4602 - val_loss: 123.9620 - learning_rate: 1.2500e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - MAE: 422.7495 - loss: 422.2502 - val_MAE: 123.0834 - val_loss: 122.5853 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 7) Build & train the model\n",
    "# ---------------------------\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = build_model(input_dim=X_train_tf.shape[1])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-5\n",
    "    ),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_tf, y_train.values,\n",
    "    validation_data=(X_val_tf, y_val.values),\n",
    "    epochs=200,\n",
    "    batch_size=256,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9527680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Set Performance ===\n",
      "R²:   0.9995\n",
      "RMSE: 129,738.59\n",
      "MAE:  125.90\n",
      "Accuracy (within ±10%): 98.12%\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 8) Evaluate (“accuracy”) on the held-out test set\n",
    "# ---------------------------\n",
    "y_pred = model.predict(X_test_tf, verbose=0).ravel()\n",
    "\n",
    "r2  = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# % within 10% of true price (an intuitive accuracy-like metric)\n",
    "within_10pct = np.mean(np.abs(y_pred - y_test.values) <= 0.10 * np.abs(y_test.values))\n",
    "\n",
    "print(\"\\n=== Test Set Performance ===\")\n",
    "print(f\"R²:   {r2:0.4f}\")\n",
    "print(f\"RMSE: {rmse:,.2f}\")\n",
    "print(f\"MAE:  {mae:,.2f}\")\n",
    "print(f\"Accuracy (within ±10%): {within_10pct*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05e0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to C:\\Users\\Georg\\OneDrive\\Dokument\\TradingBot\\car_price_model.keras\n",
      "Saved preprocessor to C:\\Users\\Georg\\OneDrive\\Dokument\\TradingBot\\preprocessor.joblib\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 9) Save model + preprocessor\n",
    "# ---------------------------\n",
    "\n",
    "MODEL_DIR = Path(r\"C:\\Users\\Georg\\OneDrive\\Dokument\\TradingBot\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Save Keras model file\n",
    "model_path = MODEL_DIR / \"car_price_model.keras\"   # note the .keras extension\n",
    "model.save(model_path)\n",
    "\n",
    "# 2) Save the preprocessor\n",
    "joblib.dump(preprocessor, MODEL_DIR / \"preprocessor.joblib\")\n",
    "\n",
    "print(f\"Saved model to {model_path}\")\n",
    "print(f\"Saved preprocessor to {MODEL_DIR/'preprocessor.joblib'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa2ffc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'Manufacturer': 'Ford', 'Model': 'Fiesta', 'Fuel type': 'Petrol', 'Engine size': 2.0, 'Year of manufacture': 2021, 'Mileage': 100000}\n",
      "Predicted price: 19,003.19\n"
     ]
    }
   ],
   "source": [
    "# === 3) Load the preprocessor ===\n",
    "preprocessor = joblib.load(MODEL_DIR / \"preprocessor.joblib\")\n",
    "\n",
    "# === 4) Create an example car to predict ===\n",
    "example = {\n",
    "    \"Manufacturer\": \"Ford\",\n",
    "    \"Model\": \"Fiesta\",\n",
    "    \"Fuel type\": \"Petrol\",\n",
    "    \"Engine size\": 2.0,               # liters\n",
    "    \"Year of manufacture\": 2021,\n",
    "    \"Mileage\": 100000                  # km or miles, same unit as your dataset\n",
    "}\n",
    "\n",
    "X_new = pd.DataFrame([example])\n",
    "\n",
    "# === 5) Transform + predict ===\n",
    "X_new_tf = preprocessor.transform(X_new)\n",
    "pred_price = model.predict(X_new_tf, verbose=0).ravel()[0]\n",
    "\n",
    "print(\"Input:\", X_new.to_dict(orient=\"records\")[0])\n",
    "print(f\"Predicted price: {pred_price:,.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
